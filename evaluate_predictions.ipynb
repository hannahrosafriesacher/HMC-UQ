{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import yaml\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from hmc_uq.utils.evaluation import HMCSampleEvaluation, PredictiveEvaluation\n",
    "from scipy.signal import correlate\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from hmc_uq.utils.data import SparseDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import hamiltorch\n",
    "from hmc_uq.utils.models import MLP\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'CYP'\n",
    "target_id = 1908\n",
    "nr_eval_params = 10000\n",
    "init = 'bbb'\n",
    "nr_samples = 10000\n",
    "nr_chains = 5\n",
    "step_size = 0.0013\n",
    "l = 1000\n",
    "num_input_features = 4096\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = {'train':[2,3,4], 'val': [1], 'test': [0]}\n",
    "\n",
    "ds_type = 'test'\n",
    "burnin = 4000\n",
    "fold = folds[ds_type ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = 'configs/ckpt_paths/HMC.yaml'\n",
    "with open(ckpt_path) as f:\n",
    "    ckpt_paths = yaml.load(f, Loader=yaml.FullLoader)[f'{init}init']\n",
    "\n",
    "models_config = 'configs/models/HMC.yaml'\n",
    "with open(models_config) as f:\n",
    "    models_configs = yaml.load(f, Loader=yaml.FullLoader)   \n",
    "\n",
    "ckpt_paths = list(ckpt_paths.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "target_info = models_configs[target]\n",
    "hidden_sizes = target_info['hidden_sizes']\n",
    "nr_layers = target_info['nr_layers']\n",
    "tau_list = [target_info['weight_decay']]\n",
    "tau_list = torch.tensor(tau_list).to(device)\n",
    "tau_out = target_info['tau_out']\n",
    "dropout = 0\n",
    "model_loss = 'binary_class_linear_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_info = models_configs[target]\n",
    "hidden_sizes = target_info['hidden_sizes']\n",
    "nr_layers = target_info['nr_layers']\n",
    "#l = target_info['L']\n",
    "#step_size = target_info['step_size']\n",
    "\n",
    "parameter_sizes = [4096 * hidden_sizes, hidden_sizes]\n",
    "for layer in range(nr_layers - 1):\n",
    "    parameter_sizes.append(hidden_sizes * hidden_sizes, hidden_sizes)\n",
    "parameter_sizes.extend([hidden_sizes, 1])\n",
    "\n",
    "\n",
    "param_names = []\n",
    "for i in range(nr_layers + 1):\n",
    "    for t in ['weight', 'bias']:\n",
    "        param_names.append(f'{t}.{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_singleTask = np.load('data/chembl_29/chembl_29_X.npy', allow_pickle=True).item().tocsr()\n",
    "Y_singleTask = np.load('data/chembl_29/chembl_29_thresh.npy', allow_pickle=True).item().tocsr()[:,target_id]\n",
    "folding=np.load('data/chembl_29/folding.npy')\n",
    "\n",
    "dataset = SparseDataset(X_singleTask, Y_singleTask, folding, fold, device)\n",
    "dataloader = DataLoader(dataset, batch_size=200, shuffle=True)\n",
    "\n",
    "fp, labels = dataset.__getdatasets__()\n",
    "labels = labels.squeeze(dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    "### *if no prediction, yet*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Samples and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(burnin, chain, ckpt_paths, parameter_sizes, return_layer = True):\n",
    "    params = np.load(f'{ckpt_paths[chain]}.npy')[:, burnin:10000]\n",
    "    \n",
    "    if return_layer:\n",
    "        cumsum = np.cumsum(parameter_sizes)[:-1]\n",
    "        params= np.array_split(params, cumsum, axis = 2)\n",
    "        return params\n",
    "    else:\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_chains = []\n",
    "for chain in range(nr_chains):\n",
    "    params = load_params(4000, chain, ckpt_paths, parameter_sizes, return_layer=False)[0]\n",
    "    net = MLP(\n",
    "        input_features=num_input_features, \n",
    "        output_features=1,\n",
    "        nr_layers=nr_layers,\n",
    "        hidden_sizes=hidden_sizes,          \n",
    "        dropout=dropout\n",
    "        )\n",
    "\n",
    "    params_torch = torch.unbind(torch.from_numpy(params))\n",
    "    \n",
    "    preds, _ = hamiltorch.predict_model(net, test_loader = dataloader, samples=params_torch, model_loss=model_loss, tau_out=tau_out, tau_list=tau_list)\n",
    "    preds = torch.squeeze(preds, 2)  \n",
    "    preds_chains.append(preds)\n",
    "\n",
    "preds_chains = torch.stack(preds_chains)\n",
    "preds_chains = F.sigmoid(preds_chains)\n",
    "preds_chains = np.reshape(preds_chains, (-1, len(labels))).mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'results/predictions/HMC/{target_id}_e{step_size}_l{l}_nrs{nr_samples}_nrc{nr_chains}_{init}init_{ds_type}'\n",
    "np.save(file_name, preds_chains.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Prediction\n",
    "### *if prediction already exists*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'results/predictions/HMC/{target_id}_e{step_size}_l{l}_nrs{nr_samples}_nrc{nr_chains}_{init}init_{ds_type}.npy'\n",
    "preds_chains = np.load(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = PredictiveEvaluation(preds_chains, labels, ds_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc        nll       ece       ace        bs\n",
      "0  0.495606  52.312923  0.276079  0.276079  0.276213\n"
     ]
    }
   ],
   "source": [
    "results = eval.evaluate()\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
